---
title: "Project 8"
output:
  html_document:
    df_print: paged
  pdf_document: default
---
Name: Max Lindquist


```{r}
# Add to this package list for additional SL algorithms

#tinytex::install_tinytex()

pacman::p_load(
  tidyverse,
  ggthemes,
  ltmle,
  tmle,
  SuperLearner,
  tidymodels,
  caret,
  dagitty,
  ggdag,
  here,
  tinytex)

heart_disease <- read_csv('heart_disease_tmle.csv')
head(heart_disease)

heart_disease <- heart_disease %>%
  # Recoding college_educ
  mutate(college_educ = case_when(
    college_educ == 2 ~ 1,
    college_educ == 1 ~ 0,
    TRUE ~ college_educ  # Keeps other values unchanged, if any
  )) 
  # Recoding simplified_race
  heart_disease <- heart_disease %>%
  mutate(White_Caucasian = if_else(simplified_race == 1, 1, 0),
         Black_African_American = if_else(simplified_race == 2, 1, 0),
         Latinx = if_else(simplified_race == 3, 1, 0),
         Asian_American = if_else(simplified_race == 4, 1, 0),
         Mixed_Race_Other = if_else(simplified_race == 5, 1, 0))

# Check the changes
head(heart_disease)

```

# Introduction

Heart disease is the leading cause of death in the United States, and treating it properly is an important public health goal. However, it is a complex disease with several different risk factors and potential treatments. Physicians typically recommend changes in diet, increased exercise, and/or medication to treat symptoms, but it is difficult to determine how effective any one of these factors is in treating the disease. In this project, you will explore SuperLearner, Targeted Maximum Likelihood Estimation (TMLE), and Longitudinal Targeted Maximum Likelihood Estimation (LTMLE). Using a simulated dataset, you will explore whether taking blood pressure medication reduces mortality risk. 

# Data

This dataset was simulated using R (so it does not come from a previous study or other data source). It contains several variables:

\begin{itemize}
    \item \textbf{blood\_pressure\_medication}: Treatment indicator for whether the individual took blood pressure medication (0 for control, 1 for treatment)
    \item \textbf{mortality}: Outcome indicator for whether the individual passed away from complications of heart disease (0 for no, 1 for yes)
    \item \textbf{age}: Age at time 1
    \item \textbf{sex\_at\_birth}: Sex assigned at birth (0 female, 1 male)
    \item \textbf{simplified\_race}: Simplified racial category. (1: White/Caucasian, 2: Black/African American, 3: Latinx, 4: Asian American, \newline 5: Mixed Race/Other)
    \item \textbf{income\_thousands}: Household income in thousands of dollars
    \item \textbf{college\_educ}: Indicator for college education (0 for no, 1 for yes)
    \item \textbf{bmi}: Body mass index (BMI)
    \item \textbf{chol}: Cholesterol level
    \item \textbf{blood\_pressure}: Systolic blood pressure 
    \item \textbf{bmi\_2}: BMI measured at time 2
    \item \textbf{chol\_2}: Cholesterol measured at time 2
    \item \textbf{blood\_pressure\_2}: BP measured at time 2
    \item \textbf{blood\_pressure\_medication\_2}: Whether the person took treatment at time period 2 
\end{itemize}

For the "SuperLearner" and "TMLE" portions, you can ignore any variable that ends in "\_2", we will reintroduce these for LTMLE.

# SuperLearner

## Modeling

Fit a SuperLearner model to estimate the probability of someone dying from complications of heart disease, conditional on treatment and the relevant covariates. Do the following:

\begin{enumerate}
    \item Choose a library of at least 5 machine learning algorithms to evaluate. \textbf{Note}: We did not cover how to hyperparameter tune constituent algorithms within SuperLearner in lab, but you are free to do so if you like (though not required to for this exercise). 
    \item Split your data into train and test sets.
    \item Train SuperLearner
    \item Report the risk and coefficient associated with each model, and the performance of the discrete winner and SuperLearner ensemble
    \item Create a confusion matrix and report your overall accuracy, recall, and precision
\end{enumerate}

```{r}
# Fit SuperLearner Model
listWrappers()

```
```{r}
sl_select <- c('SL.mean',
               'SL.glmnet',
               'SL.ridge',
               'SL.gam',
               'SL.rpartPrune')


## Train/Test split
# ----------
heart_split <- 
  initial_split(heart_disease, prop = 3/4) # create initial split (tidymodels)


# Training 
# ----------
train <- 
  # Declare the training set with rsample::training()
  training(heart_split)

# y_train 
y_train <- 
  train %>% 
  pull(mortality)    

# x_train  
x_train <-
  train %>%
  # drop the target variable
  dplyr::select(-mortality, -simplified_race, -bmi_2, -blood_pressure_2,-chol_2,-blood_pressure_medication_2)   

test <-  
  # Declare the training set with rsample::training()
  testing(heart_split)

# y test
y_test <- 
  test %>%
  pull(mortality)

# x test
x_test <- 
  test %>%
  dplyr::select(-mortality, -simplified_race,-bmi_2, -blood_pressure_2,-chol_2,-blood_pressure_medication_2)   


## Train SuperLearner

# set seed
set.seed(12345)


heart_sl <- SuperLearner(Y = y_train,              # target
                         X = x_train,              # features
                         family = binomial(),      # binomial : 1,0s
                         SL.library = sl_select) # find the glmnet algo from SL

# predictions
# ----------
preds <- 
  predict(heart_sl,             # use the superlearner not individual models
          x_test,         # prediction on test set
          onlySL = TRUE)  # use only models that were found to be useful (had weights)


# start with y_test
validation <- 
  y_test %>%
  # add our predictions - first column of predictions
  bind_cols(preds$pred[,1]) %>% 
  # rename columns
  rename(obs = `...1`,      # actual observations 
         pred = `...2`) %>% # predicted prob
  # change pred column so that obs above .5 are 1, otherwise 0
  mutate(pred = ifelse(pred >= .5, 
                           1,
                           0))




## Risk and Coefficient of each model
heart_sl

## Discrete winner and superlearner ensemble performance
heart_sl$cvRisk[which.min(heart_sl$cvRisk)]

## Confusion Matrix
caret::confusionMatrix(as.factor(validation$pred),
                       as.factor(validation$obs))
```

## Discussion Questions

Question: Why should we, in general, prefer the SuperLearner ensemble to the discrete winner in cross-validation? Or in other words, what is the advantage of "blending" algorithms together and giving them each weights, rather than just using the single best algorithm (with best being defined as minimizing risk)?

Answer: Broadly speaking, blending models with SuperLearner lets us leverage the strengths of multiple models through weights.  While a single model may perform outperform others in cross-validation  on a particular dataset, it might not perform equally well across different samples of data. By blending multiple models, SuperLearner typically achieves more stable and consistent performance across various datasets because the ensemble's overall variance is reduced.


# Targeted Maximum Likelihood Estimation

## Causal Diagram

TMLE requires estimating two models:

\begin{enumerate}
    \item The outcome model, or the relationship between the outcome and the treatment/predictors, $P(Y|(A,W)$.
    \item The propensity score model, or the relationship between assignment to treatment and predictors $P(A|W)$
\end{enumerate}

Using ggdag and daggity, draw a directed acylcic graph (DAG) that describes the relationships between the outcome, treatment, and covariates/predictors. Note, if you think there are covariates that are not related to other variables in the dataset, note this by either including them as freestanding nodes or by omitting them and noting omissions in your discussion.

```{r}
# DAG for TMLE
dag <- dagitty('dag {
  "Blood Pressure" -> "Medication"
  "BMI" -> "Blood Pressure"
  "Chol" -> "Blood Pressure"
  "Age" -> "Blood Pressure"; "Age" -> "Mortality"
  "Sex" -> "Mortality"
  "Race" -> "Mortality"
  "College" -> "Income"
  "College" -> "BMI"
  "Race" -> "BMI"
  "Income" -> "Mortality"
  "Medication" -> "Mortality"
  "BMI" -> "Mortality"
  "Blood Pressure" -> "Mortality"
  "Income" -> "BMI"
  "Race" -> "Income"
  "Race" -> "College"
}')

# Plot the DAG
ggdag(dag) +
  geom_dag_point(size = 20) +  # Increase node size
  geom_dag_edges(size = 15) +
  geom_dag_text(size = 2) +  # Add text labels
  theme_dag_blank()

```

## TMLE Estimation

Use the `tmle` package to estimate a model for the effect of blood pressure medication on the probability of mortality. Do the following:

\begin{enumerate}
    \item Use the same SuperLearner library you defined earlier
    \item Use the same outcome model and propensity score model that you specified in the DAG above. If in your DAG you concluded that it is not possible to make a causal inference from this dataset, specify a simpler model and note your assumptions for this step.
    \item Report the average treatment effect and any other relevant statistics
\end{enumerate}

```{r}

x_train2 <-
  x_train %>%
  # drop the target variable
  dplyr::select(-blood_pressure_medication) 

treatment_train <- x_train %>%
  dplyr::select(blood_pressure_medication) %>%
  dplyr::pull()

set.seed(123)


tmle_fit <- tmle(Y = y_train, 
                 A = treatment_train, 
                 W = x_train2, 
                 family = "binomial",
                 Q.SL.library = sl_select,  # For the outcome model
                 g.SL.library = sl_select)


tmle_fit
```
## Discussion Questions

Question: What is a "double robust" estimator? Why does it provide a guarantee of consistency if either the outcome model or propensity score model is correctly specified? Or in other words, why does mispecifying one of the models not break the analysis? Hint: When answering this question, think about how your introductory statistics courses emphasized using theory to determine the correct outcome model, and in this course how we explored the benefits of matching.

Answer: A double robust estimator guarantees consistency if either the outcome model or the propensity score model is correctly specified. This consistency is possible because the estimator uses two models: one for outcomes based on covariates and treatment, and another for estimating treatment assignment probabilities. If the propensity score model is accurate, it corrects for confounding, allowing for a fair comparison between treated and untreated groups even if the outcome model is wrong. On the other hand, a correct outcome model can compensate for inaccuracies in the propensity score model, ensuring that the estimation of treatment effects remains unbiased.


# LTMLE Estimation

Now imagine that everything you measured up until now was in "time period 1". Some people either choose not to or otherwise lack access to medication in that time period, but do start taking the medication in time period 2. Imagine we measure covariates like BMI, blood pressure, and cholesterol at that time for everyone in the study (indicated by a "_2" after the covariate name). 

## Causal Diagram

Update your causal diagram to incorporate this new information. \textbf{Note}: If your groups divides up sections and someone is working on LTMLE separately from TMLE then just draw a causal diagram even if it does not match the one you specified above.

\textbf{Hint}: Check out slide 27 from Maya's lecture, or slides 15-17 from Dave's second slide deck in week 8 on matching.

\textbf{Hint}: Keep in mind that any of the variables that end in "\_2" are likely affected by both the previous covariates and the first treatment when drawing your DAG.

```{r}
# DAG for TMLE

# DAG for TMLE
dag2 <- dagitty('dag {
  "BP_1" -> "Medication_1"
  "BMI_1" -> "BP_1"
  "Chol_1" -> "BP_1"
  "Age" -> "BP_1"; "Age" -> "Mortality"
  "Sex" -> "Mortality"
  "Race" -> "Mortality"
  "College" -> "Income"
  "College" -> "BMI_1"
  "Race" -> "BMI_1"
  "Income" -> "Mortality"
  "Medication_1" -> "Mortality"
  "BMI_1" -> "Mortality"
  "BP_1" -> "Mortality"
  "Income" -> "BMI_1"
  "Race" -> "Income"
  "Race" -> "College"
    "BP_2" -> "Medication_2"
    "Medication_1" -> "Medication_2"
"BMI_2" -> "BP_2"
  "Chol_2" -> "BP_2"
  "Medication_2" -> "Mortality"
  "BMI_2" -> "Mortality"
  "BP_2" -> "Mortality"
    "Chol_1" -> "Chol_2"
    "BMI_1" -> "BMI_2"
    "BP_1" -> "BP_2"
}')




ggdag(dag2) +
  geom_dag_point(size = 20) +  
  geom_dag_edges(size = 15) +
  geom_dag_text(size = 2) +  
  theme_dag_blank()

```

## LTMLE Estimation

Use the `ltmle` package for this section. First fit a "naive model" that \textbf{does not} control for the time-dependent confounding. Then run a LTMLE model that does control for any time dependent confounding. Follow the same steps as in the TMLE section. Do you see a difference between the two estimates?

```{r}
## Naive Model (no time-dependent confounding) estimate
# Prepare your data
naive_data <- heart_disease %>%
  select(age, sex_at_birth, income_thousands, college_educ, bmi, chol, blood_pressure, blood_pressure_medication, mortality) %>%
  rename(W1 = age, W2 = sex_at_birth, W3 = income_thousands, W4 = college_educ, W5 = bmi, W6 = chol, W7 = blood_pressure,
         A = blood_pressure_medication, Y = mortality)
set.seed(123)

# Fit the naive LTMLE model
naive_ltmle_result <- ltmle(naive_data,  # Dataset prepared with specific variable names
                            Anodes = "A",  # Treatment variable
                            Ynodes = "Y",  # Outcome variable
                            abar = 1,
                            SL.library = sl_select)  # Specific treatment level to estimate the effect for
naive_ltmle_result
```

```{r}
naive_data2 <- heart_disease %>%
  select(age, sex_at_birth, income_thousands, college_educ, 
         bmi, chol, blood_pressure, 
         blood_pressure_medication, chol_2, blood_pressure_2, 
         blood_pressure_medication_2, mortality) %>%
  rename(W1 = age, W2 = sex_at_birth, W3 = income_thousands, 
         W4 = college_educ, W5 = bmi, L1a = chol, L1b = blood_pressure, 
         L2a = chol_2, L2b = blood_pressure_2,  # Lnodes are all before A and Y nodes
         A1 = blood_pressure_medication, 
         A2 = blood_pressure_medication_2, 
         Y = mortality)

set.seed(123)

ltmle_result <- ltmle(naive_data2,  
                      Anodes = c("A1", "A2"),  # Treatment variables
                      Lnodes = c("L1a", "L1b", "L2a", "L2b"),  # Time-varying covariates
                      Ynodes = "Y",  # Outcome variable should be after all Lnodes and Anodes
                      abar = c(1, 1),  # Specific treatment level
                      SL.library = sl_select)

# Print the result
print(ltmle_result)


```
Controlling for time-dependent confounding slightly decreases the the estimate.
## Discussion Questions

Question: What sorts of time-dependent confounding should we be especially worried about? For instance, would we be concerned about a running variable for age the same way we might be concerned about blood pressure measured at two different times?

Answer: We should be most concerned with blood pressure,cholesterol, and BMI levels because these can change over time and are likely affected by the initial treatment. For example,  individuals who receive blood pressure medication at t1 may have lower pressure levels over time. However, these improvements in blood pressure could also be affected by other concurrent lifestyle changes, such as changes in diet, or exercise. If changes in blood pressure levels are associated with changes in mortality risk, failing to account for these time-varying changes could lead to biased estimates of treatment effects. Similar examples would follow for cholesterol and BMI levels. This is an issue for the native TMLE model that does not control for time-dependent confounding.

Some of the baseline covariates--specifically college education, income, and age--also change over time and and influence treatment selection. Increases in income or education levels may improve access to healthcare or treatment adherence, while age might affect treatment selection and effects. Because these are baseline variables at T1, neither the native nor the time-dependent TMLE models can control for their unobserved T2 variants, which introduces bias into our estimates.
